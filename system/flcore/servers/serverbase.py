import torch
import os
import numpy as np
import h5py
import copy
import time
import random
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from utils.data_utils import read_client_data
from utils.dlg import DLG


class Server(object):
    def __init__(self, args, times):
        # Set up the main attributes
        self.args = args
        self.device = args.device
        self.dataset = args.dataset
        self.num_classes = args.num_classes
        self.global_rounds = args.global_rounds
        self.local_epochs = args.local_epochs
        self.batch_size = args.batch_size
        self.learning_rate = args.local_learning_rate
        self.global_model = copy.deepcopy(args.model)
        self.num_clients = args.num_clients
        self.join_ratio = args.join_ratio
        self.random_join_ratio = args.random_join_ratio
        self.num_join_clients = int(self.num_clients * self.join_ratio)
        self.current_num_join_clients = self.num_join_clients
        self.algorithm = args.algorithm
        self.time_select = args.time_select
        self.goal = args.goal
        self.time_threthold = args.time_threthold
        self.save_folder_name = args.save_folder_name
        self.top_cnt = args.top_cnt
        self.auto_break = args.auto_break

        self.clients = []
        self.selected_clients = []
        self.train_slow_clients = []
        self.send_slow_clients = []

        self.uploaded_weights = []
        self.uploaded_ids = []
        self.uploaded_models = []

        self.rs_test_acc = []
        self.rs_test_auc = []
        self.rs_train_loss = []
        # Track global model accuracy per round (if computed)
        self.rs_global_acc = []
        
        # Time cost per round
        self.Budget = []

        self.times = times
        self.eval_gap = args.eval_gap
        self.client_drop_rate = args.client_drop_rate
        self.train_slow_rate = args.train_slow_rate
        self.send_slow_rate = args.send_slow_rate

        self.dlg_eval = args.dlg_eval
        self.dlg_gap = args.dlg_gap
        self.batch_num_per_client = args.batch_num_per_client

        self.num_new_clients = args.num_new_clients
        self.new_clients = []
        self.eval_new_clients = False
        self.fine_tuning_epoch_new = args.fine_tuning_epoch_new
        
        # Global test dataset for true global evaluation (aligned with source code)
        self.global_testloader = None
        self.load_global_test_data()

    def load_global_test_data(self):
        """
        Load complete global test dataset for true global evaluation.
        This is aligned with source code evaluation:
        - CReFF: global_model.global_eval(ft_params, data_global_test, ...)
        - CLIP2FL: global_model.global_eval(ft_params, data_global_test, ...)
        - FedGraB: DataLoader(dataset=test_dataset, ...)
        - FedNH: server_side_client.testloader (global testdataset)
        
        The global_test.npz is generated by generate_xxx.py (e.g., generate_Cifar10.py)
        and contains the complete balanced test set for global evaluation.
        """
        global_test_npz = os.path.join('../dataset', self.dataset, 'global_test.npz')
        
        if os.path.exists(global_test_npz):
            self._load_global_test_from_npz(global_test_npz)
        else:
            print(f"[Server] Warning: global_test.npz not found at {global_test_npz}")
            print(f"[Server] Please regenerate your dataset using generate_xxx.py")
            self.global_testloader = None
    
    def _load_global_test_from_npz(self, npz_path):
        """
        Load global test set from dataset's global_test.npz file.
        This is the preferred method as it's self-contained within the dataset directory.
        """
        from torchvision import transforms
        from torch.utils.data import TensorDataset
        
        print(f"[Server] Loading global test set from: {npz_path}")
        
        # Load data from npz
        with np.load(npz_path, allow_pickle=True) as f:
            data = f['data'].item()
            images = data['x']  # (N, 32, 32, 3), uint8
            labels = data['y']  # (N,)
        
        # Determine normalization based on dataset type
        dataset_name = self.dataset.lower()
        if 'cifar100' in dataset_name:
            mean = (0.5071, 0.4867, 0.4408)
            std = (0.2675, 0.2565, 0.2761)
        elif 'cifar10' in dataset_name:
            mean = (0.4914, 0.4822, 0.4465)
            std = (0.2023, 0.1994, 0.2010)
        elif 'mnist' in dataset_name:
            mean = (0.1307,)
            std = (0.3081,)
        elif 'fmnist' in dataset_name or 'fashionmnist' in dataset_name:
            mean = (0.2860,)
            std = (0.3530,)
        else:
            mean = (0.5, 0.5, 0.5)
            std = (0.5, 0.5, 0.5)
        
        # Convert to tensor and normalize
        # images: (N, H, W, C) uint8 -> (N, C, H, W) float32 normalized
        images = torch.from_numpy(images).float()
        images = images.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)
        images = images / 255.0  # [0, 255] -> [0, 1]
        
        # Apply normalization
        mean_tensor = torch.tensor(mean).view(1, -1, 1, 1)
        std_tensor = torch.tensor(std).view(1, -1, 1, 1)
        images = (images - mean_tensor) / std_tensor
        
        labels = torch.from_numpy(labels).long()
        
        # Create dataset and dataloader
        test_dataset = TensorDataset(images, labels)
        self.global_testloader = DataLoader(test_dataset, batch_size=128, shuffle=False)
        
        print(f"[Server] Loaded global test set: {len(test_dataset)} samples (from global_test.npz)")

    def set_clients(self, clientObj):
        for i, train_slow, send_slow in zip(range(self.num_clients), self.train_slow_clients, self.send_slow_clients):
            train_data = read_client_data(self.dataset, i, is_train=True)
            test_data = read_client_data(self.dataset, i, is_train=False)
            client = clientObj(self.args, 
                            id=i, 
                            train_samples=len(train_data), 
                            test_samples=len(test_data), 
                            train_slow=train_slow, 
                            send_slow=send_slow)
            self.clients.append(client)

    # random select slow clients
    def select_slow_clients(self, slow_rate):
        slow_clients = [False for i in range(self.num_clients)]
        idx = [i for i in range(self.num_clients)]
        idx_ = np.random.choice(idx, int(slow_rate * self.num_clients))
        for i in idx_:
            slow_clients[i] = True

        return slow_clients

    def set_slow_clients(self):
        self.train_slow_clients = self.select_slow_clients(
            self.train_slow_rate)
        self.send_slow_clients = self.select_slow_clients(
            self.send_slow_rate)

    def select_clients(self):
        if self.random_join_ratio:
            self.current_num_join_clients = np.random.choice(range(self.num_join_clients, self.num_clients+1), 1, replace=False)[0]
        else:
            self.current_num_join_clients = self.num_join_clients
        selected_clients = list(np.random.choice(self.clients, self.current_num_join_clients, replace=False))

        return selected_clients

    def send_models(self):
        assert (len(self.clients) > 0)

        for client in self.clients:
            start_time = time.time()
            
            client.set_parameters(self.global_model)

            client.send_time_cost['num_rounds'] += 1
            client.send_time_cost['total_cost'] += 2 * (time.time() - start_time)

    def receive_models(self):
        assert (len(self.selected_clients) > 0)

        active_clients = random.sample(
            self.selected_clients, int((1-self.client_drop_rate) * self.current_num_join_clients))

        self.uploaded_ids = []
        self.uploaded_weights = []
        self.uploaded_models = []
        tot_samples = 0
        for client in active_clients:
            try:
                client_time_cost = client.train_time_cost['total_cost'] / client.train_time_cost['num_rounds'] + \
                        client.send_time_cost['total_cost'] / client.send_time_cost['num_rounds']
            except ZeroDivisionError:
                client_time_cost = 0
            if client_time_cost <= self.time_threthold:
                tot_samples += client.train_samples
                self.uploaded_ids.append(client.id)
                self.uploaded_weights.append(client.train_samples)
                self.uploaded_models.append(client.model)
        for i, w in enumerate(self.uploaded_weights):
            self.uploaded_weights[i] = w / tot_samples

    def aggregate_parameters(self):
        assert (len(self.uploaded_models) > 0)
        # 原始：直接按收到的客户端模型与样本权重做加权平均
        self.global_model = copy.deepcopy(self.uploaded_models[0])
        for param in self.global_model.parameters():
            param.data.zero_()

        for w, client_model in zip(self.uploaded_weights, self.uploaded_models):
            self.add_parameters(w, client_model)

    def add_parameters(self, w, client_model):
        for server_param, client_param in zip(self.global_model.parameters(), client_model.parameters()):
            server_param.data += client_param.data.clone() * w

    def save_global_model(self):
        # 上游风格：统一保存到 system/models/<algorithm>_server.pt
        base_dir = os.path.dirname(os.path.abspath(__file__))
        models_root = os.path.normpath(os.path.join(base_dir, '..', '..', 'models'))
        os.makedirs(models_root, exist_ok=True)
        model_path = os.path.join(models_root, f"{self.algorithm}_server.pt")

        try:
            torch.save(self.global_model, model_path)
            print(f"Global model saved to: {os.path.abspath(model_path)}")
        except Exception as e:
            print(f"Warning: Could not save global model: {e}")

    def load_model(self):
        base_dir = os.path.dirname(os.path.abspath(__file__))
        models_root = os.path.normpath(os.path.join(base_dir, '..', '..', 'models'))
        model_path = os.path.join(models_root, f"{self.algorithm}_server.pt")

        assert os.path.exists(model_path), f"Model path not found: {model_path}"
        self.global_model = torch.load(model_path)

    def model_exists(self):
        base_dir = os.path.dirname(os.path.abspath(__file__))
        models_root = os.path.normpath(os.path.join(base_dir, '..', '..', 'models'))
        model_path = os.path.join(models_root, f"{self.algorithm}_server.pt")
        return os.path.exists(model_path)

    def save_results(self):
        # Use dataset + algorithm + timestamp as base filename
        ts = time.strftime("%Y%m%d_%H%M%S")
        base_name = f"{self.dataset}_{self.algorithm}_{ts}"
        # Anchor results under the repository's `results` folder to avoid CWD issues
        base_dir = os.path.dirname(os.path.abspath(__file__))
        result_root = os.path.normpath(os.path.join(base_dir, '..', '..', '..', 'results'))
        run_dir = os.path.join(result_root, base_name)
        os.makedirs(run_dir, exist_ok=True)

        if len(self.rs_test_acc):
            file_path = os.path.join(run_dir, f"{base_name}.h5")
            print("File path: " + file_path)

            with h5py.File(file_path, 'w') as hf:
                hf.create_dataset('rs_test_acc', data=self.rs_test_acc)
                hf.create_dataset('rs_test_auc', data=self.rs_test_auc)
                hf.create_dataset('rs_train_loss', data=self.rs_train_loss)
                if len(self.rs_global_acc):
                    hf.create_dataset('rs_global_acc', data=self.rs_global_acc)

            # Generate and save Test Accuracy curve as SVG
            try:
                # x 从 0 开始，长度与 rs_test_acc 一致
                rounds = list(range(len(self.rs_test_acc)))
                y = self.rs_test_acc

                plt.figure(figsize=(7, 4), dpi=150)
                plt.plot(rounds, y, marker='o', linewidth=1.8, markersize=3, label='Local Test Accuracy')
                plt.xlabel('Round')
                plt.ylabel('Test Accuracy')
                plt.title(f'{self.dataset}-{self.algorithm}: Local Test Accuracy per Round')
                plt.grid(True, alpha=0.3)
                plt.legend()

                # 设置 x 轴刻度为整数，从 0 开始；当轮数很多时自动稀疏显示
                if len(rounds) <= 20:
                    plt.xticks(rounds)
                else:
                    step = max(1, len(rounds) // 20)
                    plt.xticks(list(range(0, rounds[-1] + 1, step)))

                # 取消每个点的数值标注，避免在轮次较多时遮挡曲线
                # （如果需要恢复，请在此处添加标注代码）

                plt.tight_layout()
                svg_path = os.path.join(run_dir, f"{base_name}.svg")
                plt.savefig(svg_path, format='svg')
                plt.close()
                print("Saved Local Test Accuracy curve: " + svg_path)
            except Exception as e:
                print("Warning: failed to save Test Accuracy curve:", e)
            # Generate and save Global Test Accuracy curve as SVG (if available)
            try:
                if len(self.rs_global_acc):
                    g_rounds = list(range(len(self.rs_global_acc)))
                    g_y = self.rs_global_acc

                    plt.figure(figsize=(7, 4), dpi=150)
                    plt.plot(g_rounds, g_y, marker='s', linewidth=1.8, markersize=3, color='tab:red', label='Global Test Accuracy')
                    plt.xlabel('Round')
                    plt.ylabel('Test Accuracy')
                    plt.title(f'{self.dataset}-{self.algorithm}: Global Test Accuracy per Round')
                    plt.grid(True, alpha=0.3)
                    plt.legend()

                    if len(g_rounds) <= 20:
                        plt.xticks(g_rounds)
                    else:
                        g_step = max(1, len(g_rounds) // 20)
                        plt.xticks(list(range(0, g_rounds[-1] + 1, g_step)))

                    plt.tight_layout()
                    g_svg_path = os.path.join(run_dir, f"{base_name}_global.svg")
                    plt.savefig(g_svg_path, format='svg')
                    plt.close()
                    print("Saved Global Test Accuracy curve: " + g_svg_path)
            except Exception as e:
                print("Warning: failed to save Global Test Accuracy curve:", e)

    def save_item(self, item, item_name):
        if not os.path.exists(self.save_folder_name):
            os.makedirs(self.save_folder_name)
        torch.save(item, os.path.join(self.save_folder_name, "server_" + item_name + ".pt"))

    def load_item(self, item_name):
        return torch.load(os.path.join(self.save_folder_name, "server_" + item_name + ".pt"))

    def test_metrics(self):
        if self.eval_new_clients and self.num_new_clients > 0:
            self.fine_tuning_new_clients()
            return self.test_metrics_new_clients()
        
        num_samples = []
        tot_correct = []
        tot_auc = []
        for c in self.clients:
            ct, ns, auc = c.test_metrics()
            tot_correct.append(ct*1.0)
            tot_auc.append(auc*ns)
            num_samples.append(ns)

        ids = [c.id for c in self.clients]

        return ids, num_samples, tot_correct, tot_auc

    def train_metrics(self):
        if self.eval_new_clients and self.num_new_clients > 0:
            return [0], [1], [0]
        
        num_samples = []
        losses = []
        # CRITICAL: Only compute train_metrics for selected_clients that actually trained
        # Using all clients would cause issues when some have stale models or ft_params
        clients_to_eval = self.selected_clients if hasattr(self, 'selected_clients') and len(self.selected_clients) > 0 else self.clients
        
        for c in clients_to_eval:
            # Use training loss recorded during client.train() if available
            # This aligns with CReFF source code which reports training batch loss
            if hasattr(c, 'train_loss_during_training'):
                # CRITICAL: train_loss_during_training is AVERAGE loss per batch
                # We need to convert it to TOTAL loss for aggregation
                # (evaluate() will divide by total samples again)
                losses.append(c.train_loss_during_training * c.train_samples)
                num_samples.append(c.train_samples)
            else:
                # Fallback to evaluation-based train_metrics
                # This already returns total loss
                cl, ns = c.train_metrics()
                num_samples.append(ns)
                losses.append(cl*1.0)

        ids = [c.id for c in clients_to_eval]

        return ids, num_samples, losses

    @torch.no_grad()
    def compute_global_test_accuracy(self):
        """
        Compute global model accuracy on the COMPLETE global test set.
        This is aligned with source code evaluation (e.g., CReFF, CLIP2FL, FedGraB, FedNH).
        
        Returns:
            float: accuracy on global test set, or None if not available
        """
        if self.global_testloader is None:
            return None
        
        try:
            self.global_model.eval()
            correct = 0
            total = 0
            
            for images, labels in self.global_testloader:
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                outputs = self.global_model(images)
                # Handle models that return (feature, output) tuple
                if isinstance(outputs, tuple):
                    _, outputs = outputs
                
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
            
            accuracy = correct / total
            return accuracy
            
        except Exception as e:
            print(f"Warning: failed to compute global test accuracy: {e}")
            return None

    # evaluate selected clients
    def evaluate(self, acc=None, loss=None):
        stats = self.test_metrics()
        stats_train = self.train_metrics()

        test_acc = sum(stats[2])*1.0 / sum(stats[1])
        test_auc = sum(stats[3])*1.0 / sum(stats[1])
        train_loss = sum(stats_train[2])*1.0 / sum(stats_train[1])
        accs = [a / n for a, n in zip(stats[2], stats[1])]
        aucs = [a / n for a, n in zip(stats[3], stats[1])]
        
        if acc == None:
            self.rs_test_acc.append(test_acc)
        else:
            acc.append(test_acc)
        
        if loss == None:
            self.rs_train_loss.append(train_loss)
        else:
            loss.append(train_loss)

        print("Averaged Train Loss: {:.4f}".format(train_loss))
        print("Local Averaged Test Accuracy: {:.4f}".format(test_acc))
        print("Averaged Test AUC: {:.4f}".format(test_auc))
        # self.print_(test_acc, train_acc, train_loss)
        print("Std Test Accuracy: {:.4f}".format(np.std(accs)))
        print("Std Test AUC: {:.4f}".format(np.std(aucs)))
        # 计算并打印全局平均测试准确率（如可用）
        g_acc = self.compute_global_test_accuracy()
        if g_acc is not None:
            self.rs_global_acc.append(g_acc)
            print("Global Averaged Test Accuracy: {:.4f}".format(g_acc))
        else:
            # If global accuracy not available, use local accuracy as fallback
            self.rs_global_acc.append(test_acc)

    def print_(self, test_acc, test_auc, train_loss):
        print("Local Average Test Accuracy: {:.4f}".format(test_acc))
        print("Average Test AUC: {:.4f}".format(test_auc))
        print("Average Train Loss: {:.4f}".format(train_loss))

    def check_done(self, acc_lss, top_cnt=None, div_value=None):
        for acc_ls in acc_lss:
            if top_cnt is not None and div_value is not None:
                find_top = len(acc_ls) - torch.topk(torch.tensor(acc_ls), 1).indices[0] > top_cnt
                find_div = len(acc_ls) > 1 and np.std(acc_ls[-top_cnt:]) < div_value
                if find_top and find_div:
                    pass
                else:
                    return False
            elif top_cnt is not None:
                find_top = len(acc_ls) - torch.topk(torch.tensor(acc_ls), 1).indices[0] > top_cnt
                if find_top:
                    pass
                else:
                    return False
            elif div_value is not None:
                find_div = len(acc_ls) > 1 and np.std(acc_ls[-top_cnt:]) < div_value
                if find_div:
                    pass
                else:
                    return False
            else:
                raise NotImplementedError
        return True

    def call_dlg(self, R):
        # items = []
        cnt = 0
        psnr_val = 0
        for cid, client_model in zip(self.uploaded_ids, self.uploaded_models):
            client_model.eval()
            origin_grad = []
            for gp, pp in zip(self.global_model.parameters(), client_model.parameters()):
                origin_grad.append(gp.data - pp.data)

            target_inputs = []
            trainloader = self.clients[cid].load_train_data()
            with torch.no_grad():
                for i, (x, y) in enumerate(trainloader):
                    if i >= self.batch_num_per_client:
                        break

                    if type(x) == type([]):
                        x[0] = x[0].to(self.device)
                    else:
                        x = x.to(self.device)
                    y = y.to(self.device)
                    output = client_model(x)
                    target_inputs.append((x, output))

            d = DLG(client_model, origin_grad, target_inputs)
            if d is not None:
                psnr_val += d
                cnt += 1
            
            # items.append((client_model, origin_grad, target_inputs))
                
        if cnt > 0:
            print('PSNR value is {:.2f} dB'.format(psnr_val / cnt))
        else:
            print('PSNR error')

        # self.save_item(items, f'DLG_{R}')

    def set_new_clients(self, clientObj):
        for i in range(self.num_clients, self.num_clients + self.num_new_clients):
            train_data = read_client_data(self.dataset, i, is_train=True)
            test_data = read_client_data(self.dataset, i, is_train=False)
            client = clientObj(self.args, 
                            id=i, 
                            train_samples=len(train_data), 
                            test_samples=len(test_data), 
                            train_slow=False, 
                            send_slow=False)
            self.new_clients.append(client)

    # fine-tuning on new clients
    def fine_tuning_new_clients(self):
        for client in self.new_clients:
            client.set_parameters(self.global_model)
            opt = torch.optim.SGD(client.model.parameters(), lr=self.learning_rate)
            CEloss = torch.nn.CrossEntropyLoss()
            trainloader = client.load_train_data()
            client.model.train()
            for e in range(self.fine_tuning_epoch_new):
                for i, (x, y) in enumerate(trainloader):
                    if type(x) == type([]):
                        x[0] = x[0].to(client.device)
                    else:
                        x = x.to(client.device)
                    y = y.to(client.device)
                    output = client.model(x)
                    loss = CEloss(output, y)
                    opt.zero_grad()
                    loss.backward()
                    opt.step()

    # evaluating on new clients
    def test_metrics_new_clients(self):
        num_samples = []
        tot_correct = []
        tot_auc = []
        for c in self.new_clients:
            ct, ns, auc = c.test_metrics()
            tot_correct.append(ct*1.0)
            tot_auc.append(auc*ns)
            num_samples.append(ns)

        ids = [c.id for c in self.new_clients]

        return ids, num_samples, tot_correct, tot_auc
